{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9010ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/a/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/a/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /home/a/.local/lib/python3.10/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /home/a/.local/lib/python3.10/site-packages (2.8.0)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /home/a/.local/lib/python3.10/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/a/.local/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/a/.local/lib/python3.10/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/a/.local/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/a/.local/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/a/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/a/.local/lib/python3.10/site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/a/.local/lib/python3.10/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/a/.local/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/a/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/a/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/a/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/a/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/a/.local/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/a/.local/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/a/.local/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/a/.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/a/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/a/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/a/.local/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/a/.local/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/a/.local/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/a/.local/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/a/.local/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/a/.local/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/a/.local/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/a/.local/lib/python3.10/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/a/.local/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/a/.local/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/a/.local/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/a/.local/lib/python3.10/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/lib/python3/dist-packages (from triton==3.4.0->torch) (59.6.0)\n",
      "Requirement already satisfied: psutil in /home/a/.local/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/a/.local/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/a/.local/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/a/.local/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/a/.local/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/a/.local/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/a/.local/lib/python3.10/site-packages (from requests->transformers) (2025.6.15)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/a/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: accelerate\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/home/a/.local/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed accelerate-1.12.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers torch accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67eefa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f6262a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 148/148 [00:00<00:00, 1112.03it/s, Materializing param=transformer.wte.weight]            \n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 76/76 [00:00<00:00, 950.36it/s, Materializing param=transformer.wte.weight]            \n",
      "Loading weights: 100%|██████████| 149/149 [00:00<00:00, 1103.58it/s, Materializing param=transformer.wte.weight]            \n",
      "The tied weights mapping and config for this model specifies to tie transformer.wte.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "source": [
    "# Load a text generation pipeline with a small model\n",
    "generator1 = pipeline('text-generation', model='gpt2')\n",
    "# DistilGPT-2 (меньше GPT-2, быстрее)\n",
    "generator2 = pipeline('text-generation', model='distilgpt2')\n",
    "\n",
    "# DialoGPT-small (для диалогов)\n",
    "generator3 = pipeline('text-generation', model='microsoft/DialoGPT-small')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36cc6899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'max_length', 'num_return_sequences'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reccomend me a good road movie. \"\n",
      "\n",
      "The movie is titled \"The Godfather of the Furious\", and is scheduled to hit theaters on July 23, 2018.\n",
      "\n",
      "The movie is written by Andrew Garfield and stars Tom Hardy, Amy Adams, and Michael Fassbender.\n"
     ]
    }
   ],
   "source": [
    "# Generate text\n",
    "prompt = \"reccomend me a good road movie\"\n",
    "result = generator1(prompt, max_length=50, num_return_sequences=1)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db073f6",
   "metadata": {},
   "source": [
    "## Попробуем Llama 2\n",
    "\n",
    "Ниже — способ использовать Llama 2 через llama.cpp для локальной работы с квантованной моделью (CPU, компактные файлы).\n",
    "\n",
    "Внимание: Llama 2 7B; для работы нужен минимум ~4 ГБ RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc3fbbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (0.3.16)\n",
      "Requirement already satisfied: huggingface-hub in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (1.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from llama-cpp-python) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from llama-cpp-python) (2.4.2)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from llama-cpp-python) (3.1.6)\n",
      "Requirement already satisfied: filelock in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (3.24.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (1.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (6.0.3)\n",
      "Requirement already satisfied: shellingham in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (4.67.3)\n",
      "Requirement already satisfied: typer-slim in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (0.24.0)\n",
      "Requirement already satisfied: anyio in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub) (4.12.1)\n",
      "Requirement already satisfied: certifi in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub) (2026.2.25)\n",
      "Requirement already satisfied: httpcore==1.* in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.3)\n",
      "Requirement already satisfied: typer>=0.24.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub) (0.24.1)\n",
      "Requirement already satisfied: click>=8.2.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub) (14.3.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a8f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-cpp-python in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (0.3.16)\n",
      "Requirement already satisfied: huggingface-hub in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (1.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from llama-cpp-python) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from llama-cpp-python) (2.4.2)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from llama-cpp-python) (3.1.6)\n",
      "Requirement already satisfied: filelock in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (3.24.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (1.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (6.0.3)\n",
      "Requirement already satisfied: shellingham in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (4.67.3)\n",
      "Requirement already satisfied: typer-slim in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from huggingface-hub) (0.24.0)\n",
      "Requirement already satisfied: anyio in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub) (4.12.1)\n",
      "Requirement already satisfied: certifi in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub) (2026.2.25)\n",
      "Requirement already satisfied: httpcore==1.* in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->huggingface-hub) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.3)\n",
      "Requirement already satisfied: typer>=0.24.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from typer-slim->huggingface-hub) (0.24.1)\n",
      "Requirement already satisfied: click>=8.2.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub) (8.3.1)\n",
      "Requirement already satisfied: rich>=12.3.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub) (14.3.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from typer>=0.24.0->typer-slim->huggingface-hub) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/a/Desktop/rag/RAG/.venv/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface-hub) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python huggingface-hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b23f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model downloaded to: /home/a/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-Chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q4_K_M.gguf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_context: n_ctx_per_seq (2048) < n_ctx_train (4096) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "# Локально через llama.cpp\n",
    "# Установите: pip install llama-cpp-python huggingface-hub\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Download LLaMA-2 13B Chat GGUF model (Q4_K_M quantization)\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"TheBloke/Llama-2-13B-Chat-GGUF\",\n",
    "    filename=\"llama-2-13b-chat.Q4_K_M.gguf\"\n",
    ")\n",
    "print(f\"Model downloaded to: {model_path}\")\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    chat_format=\"llama-2\",\n",
    "    n_ctx=2048,\n",
    "    n_threads=8,   # можно поставить = числу физических ядер CPU\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Recommend a good road movie.\"}]\n",
    "resp = llm.create_chat_completion(messages=messages)\n",
    "\n",
    "print(resp[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "530fbe2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'huggingface_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Локально через llama.cpp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# Установите: pip install llama-cpp-python huggingface-hub\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhuggingface_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_cpp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Llama\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Download Mistral-7B-Instruct GGUF model (Q4_K_M quantization)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'huggingface_hub'"
     ]
    }
   ],
   "source": [
    "# Локально через llama.cpp\n",
    "# Установите: pip install llama-cpp-python huggingface-hub\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# Download Mistral-7B-Instruct GGUF model (Q4_K_M quantization)\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"TheBloke/Mistral-7B-Instruct-v0.1-GGUF\",\n",
    "    filename=\"mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n",
    ")\n",
    "print(f\"Model downloaded to: {model_path}\")\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    chat_format=\"mistral-instruct\",\n",
    "    n_ctx=2048,\n",
    "    n_threads=8,   # можно поставить = числу физических ядер CPU\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Recommend a good road movie.\"}]\n",
    "resp = llm.create_chat_completion(messages=messages)\n",
    "\n",
    "print(resp[\"choices\"][0][\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
